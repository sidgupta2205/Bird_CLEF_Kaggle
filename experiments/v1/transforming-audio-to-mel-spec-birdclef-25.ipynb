{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **BirdCLEF 2025 Data Preprocessing Notebook**\nThis notebook demonstrates how we can transform audio data into mel-spectrogram data. This transformation is essential for training 2D Convolutional Neural Networks (CNNs) on audio data, as it converts the one-dimensional audio signals into two-dimensional image-like representations.\nI run this public notebook in debug mode(only a few sample processing). You can find the fully preprocessed mel spectrogram training dataset here --> [BirdCLEF'25 | Mel Spectrograms](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms).\n","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport math\nimport time\nimport librosa\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T15:03:36.662910Z","iopub.execute_input":"2025-03-24T15:03:36.663277Z","iopub.status.idle":"2025-03-24T15:03:36.669926Z","shell.execute_reply.started":"2025-03-24T15:03:36.663245Z","shell.execute_reply":"2025-03-24T15:03:36.668276Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Config:\n \n    DEBUG_MODE = True\n    \n    OUTPUT_DIR = '/kaggle/working/'\n    DATA_ROOT = '/kaggle/input/birdclef-2025'\n    FS = 32000\n    \n    # Mel spectrogram parameters\n    N_FFT = 1024\n    HOP_LENGTH = 512\n    N_MELS = 128\n    FMIN = 50\n    FMAX = 14000\n    \n    TARGET_DURATION = 5.0\n    TARGET_SHAPE = (256, 256)  \n    \n    N_MAX = 50 if DEBUG_MODE else None  \n\nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T15:03:40.795717Z","iopub.execute_input":"2025-03-24T15:03:40.796059Z","iopub.status.idle":"2025-03-24T15:03:40.801584Z","shell.execute_reply.started":"2025-03-24T15:03:40.796030Z","shell.execute_reply":"2025-03-24T15:03:40.800422Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(f\"Debug mode: {'ON' if config.DEBUG_MODE else 'OFF'}\")\nprint(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")\n\nprint(\"Loading taxonomy data...\")\ntaxonomy_df = pd.read_csv(f'{config.DATA_ROOT}/taxonomy.csv')\nspecies_class_map = dict(zip(taxonomy_df['primary_label'], taxonomy_df['class_name']))\n\nprint(\"Loading training metadata...\")\ntrain_df = pd.read_csv(f'{config.DATA_ROOT}/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T15:03:50.541702Z","iopub.execute_input":"2025-03-24T15:03:50.542052Z","iopub.status.idle":"2025-03-24T15:03:50.700169Z","shell.execute_reply.started":"2025-03-24T15:03:50.542022Z","shell.execute_reply":"2025-03-24T15:03:50.699110Z"}},"outputs":[{"name":"stdout","text":"Debug mode: ON\nMax samples to process: 50\nLoading taxonomy data...\nLoading training metadata...\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train_df['primary_label'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T15:04:14.660899Z","iopub.execute_input":"2025-03-24T15:04:14.661231Z","iopub.status.idle":"2025-03-24T15:04:14.671313Z","shell.execute_reply.started":"2025-03-24T15:04:14.661206Z","shell.execute_reply":"2025-03-24T15:04:14.670272Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array(['1139490', '1192948', '1194042', '126247', '1346504', '134933',\n       '135045', '1462711', '1462737', '1564122', '21038', '21116',\n       '21211', '22333', '22973', '22976', '24272', '24292', '24322',\n       '41663', '41778', '41970', '42007', '42087', '42113', '46010',\n       '47067', '476537', '476538', '48124', '50186', '517119', '523060',\n       '528041', '52884', '548639', '555086', '555142', '566513', '64862',\n       '65336', '65344', '65349', '65373', '65419', '65448', '65547',\n       '65962', '66016', '66531', '66578', '66893', '67082', '67252',\n       '714022', '715170', '787625', '81930', '868458', '963335',\n       'amakin1', 'amekes', 'ampkin1', 'anhing', 'babwar', 'bafibi1',\n       'banana', 'baymac', 'bbwduc', 'bicwre1', 'bkcdon', 'bkmtou1',\n       'blbgra1', 'blbwre1', 'blcant4', 'blchaw1', 'blcjay1', 'blctit1',\n       'blhpar1', 'blkvul', 'bobfly1', 'bobher1', 'brtpar1', 'bubcur1',\n       'bubwre1', 'bucmot3', 'bugtan', 'butsal1', 'cargra1', 'cattyr',\n       'chbant1', 'chfmac1', 'cinbec1', 'cocher1', 'cocwoo1', 'colara1',\n       'colcha1', 'compau', 'compot1', 'cotfly1', 'crbtan1', 'crcwoo1',\n       'crebob1', 'cregua1', 'creoro1', 'eardov1', 'fotfly', 'gohman1',\n       'grasal4', 'grbhaw1', 'greani1', 'greegr', 'greibi1', 'grekis',\n       'grepot1', 'gretin1', 'grnkin', 'grysee1', 'gybmar', 'gycwor1',\n       'labter1', 'laufal1', 'leagre', 'linwoo1', 'littin1', 'mastit1',\n       'neocor', 'norscr1', 'olipic1', 'orcpar', 'palhor2', 'paltan1',\n       'pavpig2', 'piepuf1', 'pirfly1', 'piwtyr1', 'plbwoo1', 'plctan1',\n       'plukit1', 'purgal2', 'ragmac1', 'rebbla1', 'recwoo1', 'rinkin1',\n       'roahaw', 'rosspo1', 'royfly1', 'rtlhum', 'rubsee1', 'rufmot1',\n       'rugdov', 'rumfly1', 'ruther1', 'rutjac1', 'rutpuf1', 'saffin',\n       'sahpar1', 'savhaw1', 'secfly1', 'shghum1', 'shtfly1', 'smbani',\n       'snoegr', 'sobtyr1', 'socfly1', 'solsan', 'soulap1', 'spbwoo1',\n       'speowl1', 'spepar1', 'srwswa1', 'stbwoo2', 'strcuc1', 'strfly1',\n       'strher', 'strowl1', 'tbsfin1', 'thbeup1', 'thlsch3', 'trokin',\n       'tropar', 'trsowl', 'turvul', 'verfly', 'watjac1', 'wbwwre1',\n       'whbant1', 'whbman1', 'whfant1', 'whmtyr1', 'whtdov', 'whttro1',\n       'whwswa1', 'woosto', 'y00678', 'yebela1', 'yebfly1', 'yebsee1',\n       'yecspi2', 'yectyr1', 'yehbla2', 'yehcar1', 'yelori1', 'yeofly1',\n       'yercac1', 'ywcpar'], dtype=object)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"label_list = sorted(train_df['primary_label'].unique())\nlabel_id_list = list(range(len(label_list)))\nlabel2id = dict(zip(label_list, label_id_list))\nid2label = dict(zip(label_id_list, label_list))\n\nprint(f'Found {len(label_list)} unique species')\nworking_df = train_df[['primary_label', 'rating', 'filename']].copy()\nworking_df['target'] = working_df.primary_label.map(label2id)\nworking_df['filepath'] = config.DATA_ROOT + '/train_audio/' + working_df.filename\nworking_df['samplename'] = working_df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\nworking_df['class'] = working_df.primary_label.map(lambda x: species_class_map.get(x, 'Unknown'))\ntotal_samples = min(len(working_df), config.N_MAX or len(working_df))\nprint(f'Total samples to process: {total_samples} out of {len(working_df)} available')\nprint(f'Samples by class:')\nprint(working_df['class'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T14:36:10.118727Z","iopub.execute_input":"2025-03-24T14:36:10.119092Z","iopub.status.idle":"2025-03-24T14:36:10.204496Z","shell.execute_reply.started":"2025-03-24T14:36:10.119060Z","shell.execute_reply":"2025-03-24T14:36:10.203309Z"}},"outputs":[{"name":"stdout","text":"Found 206 unique species\nTotal samples to process: 50 out of 28564 available\nSamples by class:\nclass\nAves        27648\nAmphibia      583\nMammalia      178\nInsecta       155\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def audio2melspec(audio_data):\n    if np.isnan(audio_data).any():\n        mean_signal = np.nanmean(audio_data)\n        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n\n    mel_spec = librosa.feature.melspectrogram(\n        y=audio_data,\n        sr=config.FS,\n        n_fft=config.N_FFT,\n        hop_length=config.HOP_LENGTH,\n        n_mels=config.N_MELS,\n        fmin=config.FMIN,\n        fmax=config.FMAX,\n        power=2.0\n    )\n\n    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n    \n    return mel_spec_norm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:17:07.823361Z","iopub.execute_input":"2025-03-17T13:17:07.823753Z","iopub.status.idle":"2025-03-17T13:17:07.829972Z","shell.execute_reply.started":"2025-03-17T13:17:07.823724Z","shell.execute_reply":"2025-03-17T13:17:07.828954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Starting audio processing...\")\nprint(f\"{'DEBUG MODE - Processing only 50 samples' if config.DEBUG_MODE else 'FULL MODE - Processing all samples'}\")\nstart_time = time.time()\n\nall_bird_data = {}\nerrors = []\n\nfor i, row in tqdm(working_df.iterrows(), total=total_samples):\n    if config.N_MAX is not None and i >= config.N_MAX:\n        break\n    \n    try:\n        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n\n        target_samples = int(config.TARGET_DURATION * config.FS)\n\n        if len(audio_data) < target_samples:\n            n_copy = math.ceil(target_samples / len(audio_data))\n            if n_copy > 1:\n                audio_data = np.concatenate([audio_data] * n_copy)\n\n        start_idx = max(0, int(len(audio_data) / 2 - target_samples / 2))\n        end_idx = min(len(audio_data), start_idx + target_samples)\n        center_audio = audio_data[start_idx:end_idx]\n\n        if len(center_audio) < target_samples:\n            center_audio = np.pad(center_audio, \n                                 (0, target_samples - len(center_audio)), \n                                 mode='constant')\n\n        mel_spec = audio2melspec(center_audio)\n\n        if mel_spec.shape != config.TARGET_SHAPE:\n            mel_spec = cv2.resize(mel_spec, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n\n        all_bird_data[row.samplename] = mel_spec.astype(np.float32)\n        \n    except Exception as e:\n        print(f\"Error processing {row.filepath}: {e}\")\n        errors.append((row.filepath, str(e)))\n\nend_time = time.time()\nprint(f\"Processing completed in {end_time - start_time:.2f} seconds\")\nprint(f\"Successfully processed {len(all_bird_data)} files out of {total_samples} total\")\nprint(f\"Failed to process {len(errors)} files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:18:01.589211Z","iopub.execute_input":"2025-03-17T13:18:01.589636Z","iopub.status.idle":"2025-03-17T13:18:25.526712Z","shell.execute_reply.started":"2025-03-17T13:18:01.589604Z","shell.execute_reply":"2025-03-17T13:18:25.525599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsamples = []\ndisplayed_classes = set()\n\nmax_samples = min(4, len(all_bird_data))\n\nfor i, row in working_df.iterrows():\n    if i >= (config.N_MAX or len(working_df)):\n        break\n        \n    if row['samplename'] in all_bird_data:\n        if config.DEBUG_MODE:\n            if row['class'] not in displayed_classes:\n                samples.append((row['samplename'], row['class'], row['primary_label']))\n                displayed_classes.add(row['class'])\n        else:\n            if row['class'] not in displayed_classes:\n                samples.append((row['samplename'], row['class'], row['primary_label']))\n                displayed_classes.add(row['class'])\n        \n        if len(samples) >= max_samples:  \n            break\n\nif samples:\n    plt.figure(figsize=(16, 12))\n    \n    for i, (samplename, class_name, species) in enumerate(samples):\n        plt.subplot(2, 2, i+1)\n        plt.imshow(all_bird_data[samplename], aspect='auto', origin='lower', cmap='viridis')\n        plt.title(f\"{class_name}: {species}\")\n        plt.colorbar(format='%+2.0f dB')\n    \n    plt.tight_layout()\n    debug_note = \"debug_\" if config.DEBUG_MODE else \"\"\n    plt.savefig(f'{debug_note}melspec_examples.png')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:18:40.389921Z","iopub.execute_input":"2025-03-17T13:18:40.390482Z","iopub.status.idle":"2025-03-17T13:18:42.364716Z","shell.execute_reply.started":"2025-03-17T13:18:40.390449Z","shell.execute_reply":"2025-03-17T13:18:42.363415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}