{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"sourceType":"competition"},{"sourceId":11053663,"sourceType":"datasetVersion","datasetId":6886569},{"sourceId":11174347,"sourceType":"datasetVersion","datasetId":6974052},{"sourceId":11215324,"sourceType":"datasetVersion","datasetId":7003445},{"sourceId":309778,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":262881,"modelId":284001},{"sourceId":318253,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":268551,"modelId":289572},{"sourceId":319716,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":269770,"modelId":290760}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **BirdCLEF 2025 Training Notebook**\n\nThis is a baseline training pipeline for BirdCLEF 2025 using EfficientNetB0 with PyTorch and Timm(for pretrained EffNet). You can check inference and preprocessing notebooks in the following links: \n\n- [EfficientNet B0 Pytorch [Inference] | BirdCLEF'25](https://www.kaggle.com/code/kadircandrisolu/efficientnet-b0-pytorch-inference-birdclef-25)\n\n  \n- [Transforming Audio-to-Mel Spec. | BirdCLEF'25](https://www.kaggle.com/code/kadircandrisolu/transforming-audio-to-mel-spec-birdclef-25)  \n\nNote that by default this notebook is in Debug Mode, so it will only train the model with 2 epochs, but the [weight](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-effnetb0-starter-weight) I used in the inference notebook was obtained after 10 epochs of training.\n\n**Features**\n* Implement with Pytorch and Timm\n* Flexible audio processing with both pre-computed and on-the-fly mel spectrograms\n* Stratified 5-fold cross-validation with ensemble capability\n* Mixup training for improved generalization\n* Spectrogram augmentations (time/frequency masking, brightness adjustment)\n* AdamW optimizer with Cosine Annealing LR scheduling\n* Debug mode for quick experimentation with smaller datasets\n\n**Pre-computed Spectrograms**\nFor faster training, you can use pre-computed mel spectrograms from [this dataset](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms) by setting `LOAD_DATA = True`","metadata":{}},{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport logging\nimport random\nimport gc\nimport time\nimport cv2\nimport math\nimport warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport librosa\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nimport timm\n\nwarnings.filterwarnings(\"ignore\")\nlogging.basicConfig(level=logging.ERROR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:11.754720Z","iopub.execute_input":"2025-04-03T18:50:11.755102Z","iopub.status.idle":"2025-04-03T18:50:22.945112Z","shell.execute_reply.started":"2025-04-03T18:50:11.755069Z","shell.execute_reply":"2025-04-03T18:50:22.944195Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    \n    seed = 42\n    debug = False  \n    apex = False\n    print_freq = 100\n    num_workers = 2\n    \n    OUTPUT_DIR = '/kaggle/working/'\n\n    train_datadir = '/kaggle/input/birdclef-2025/train_audio'\n    train_csv = '/kaggle/input/birdclef-2025/train.csv'\n    test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'\n    submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'\n    taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n    pretrain_data = \"/kaggle/input/pretraining-dataset-ss\"\n    spectrogram_npy = '/kaggle/input/spectogram-with-start-crop/spectograms.npy'\n \n    # model_name = 'efficientnet_b0'  \n    model_name = \"custom\"\n    pretrained = True\n    in_channels = 1\n\n    LOAD_DATA = True  \n    FS = 32000\n    TARGET_DURATION = 5.0\n    TARGET_SHAPE = (256, 256)\n    \n    N_FFT = 1024\n    HOP_LENGTH = 512\n    N_MELS = 128\n    FMIN = 50\n    FMAX = 14000\n    \n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    epochs = 10  \n    batch_size = 32  \n    criterion = 'BCEWithLogitsLoss'\n\n    n_fold = 5\n    selected_folds = [0, 1, 2, 3, 4]   \n\n    optimizer = 'AdamW'\n    lr = 5e-4 \n    weight_decay = 1e-5\n  \n    scheduler = 'CosineAnnealingLR'\n    min_lr = 1e-6\n    T_max = epochs\n\n    aug_prob = 0.5  \n    mixup_alpha = 0.5  \n    \n    def update_debug_settings(self):\n        if self.debug:\n            self.epochs = 2\n            self.selected_folds = [0]\n\ncfg = CFG()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=42):\n    \"\"\"\n    Set seed for reproducibility\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(cfg.seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:26.684853Z","iopub.execute_input":"2025-04-03T18:50:26.685148Z","iopub.status.idle":"2025-04-03T18:50:26.695315Z","shell.execute_reply.started":"2025-04-03T18:50:26.685127Z","shell.execute_reply":"2025-04-03T18:50:26.694421Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Pre-processing\nThese functions handle the transformation of audio files to mel spectrograms for model input, with flexibility controlled by the `LOAD_DATA` parameter. The process involves either loading pre-computed spectrograms from this [dataset](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms) (when `LOAD_DATA=True`) or dynamically generating them (when `LOAD_DATA=False`), transforming audio data into spectrogram representations, and preparing it for the neural network.","metadata":{}},{"cell_type":"code","source":"def audio2melspec(audio_data, cfg):\n    \"\"\"Convert audio data to mel spectrogram\"\"\"\n    if np.isnan(audio_data).any():\n        mean_signal = np.nanmean(audio_data)\n        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n\n    mel_spec = librosa.feature.melspectrogram(\n        y=audio_data,\n        sr=cfg.FS,\n        n_fft=cfg.N_FFT,\n        hop_length=cfg.HOP_LENGTH,\n        n_mels=cfg.N_MELS,\n        fmin=cfg.FMIN,\n        fmax=cfg.FMAX,\n        power=2.0\n    )\n\n    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n    \n    return mel_spec_norm\n\ndef process_audio_file(audio_path, cfg):\n    \"\"\"Process a single audio file to get the mel spectrogram\"\"\"\n    try:\n        audio_data, _ = librosa.load(audio_path, sr=cfg.FS)\n\n        target_samples = int(cfg.TARGET_DURATION * cfg.FS)\n\n        if len(audio_data) < target_samples:\n            n_copy = math.ceil(target_samples / len(audio_data))\n            if n_copy > 1:\n                audio_data = np.concatenate([audio_data] * n_copy)\n\n        # Extract center 5 seconds\n        start_idx = max(0, int(len(audio_data) / 2 - target_samples / 2))\n        end_idx = min(len(audio_data), start_idx + target_samples)\n        # center_audio = audio_data[start_idx:end_idx]\n        center_audio = audio_data[0:160000]\n        \n\n        if len(center_audio) < target_samples:\n            center_audio = np.pad(center_audio, \n                                 (0, target_samples - len(center_audio)), \n                                 mode='constant')\n\n        mel_spec = audio2melspec(center_audio, cfg)\n        \n        if mel_spec.shape != cfg.TARGET_SHAPE:\n            mel_spec = cv2.resize(mel_spec, cfg.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n\n        return mel_spec.astype(np.float32)\n        \n    except Exception as e:\n        print(f\"Error processing {audio_path}: {e}\")\n        return None\n\ndef generate_spectrograms(df, cfg):\n    \"\"\"Generate spectrograms from audio files\"\"\"\n    print(\"Generating mel spectrograms from audio files...\")\n    start_time = time.time()\n\n    all_bird_data = {}\n    errors = []\n\n    for i, row in tqdm(df.iterrows(), total=len(df)):\n        if cfg.debug and i >= 1000:\n            break\n        \n        try:\n            samplename = row['samplename']\n            filepath = row['filepath']\n            \n            mel_spec = process_audio_file(filepath, cfg)\n            \n            if mel_spec is not None:\n                all_bird_data[samplename] = mel_spec\n            \n        except Exception as e:\n            print(f\"Error processing {row.filepath}: {e}\")\n            errors.append((row.filepath, str(e)))\n\n    end_time = time.time()\n    print(f\"Processing completed in {end_time - start_time:.2f} seconds\")\n    print(f\"Successfully processed {len(all_bird_data)} files out of {len(df)}\")\n    print(f\"Failed to process {len(errors)} files\")\n    \n    return all_bird_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:27.996973Z","iopub.execute_input":"2025-04-03T18:50:27.997269Z","iopub.status.idle":"2025-04-03T18:50:28.008058Z","shell.execute_reply.started":"2025-04-03T18:50:27.997249Z","shell.execute_reply":"2025-04-03T18:50:28.007284Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Dataset Preparation and Data Augmentations\nWe'll convert audio to mel spectrograms and apply random augmentations with 50% probability each - including time stretching, pitch shifting, and volume adjustments. This randomized approach creates diverse training samples from the same audio files","metadata":{}},{"cell_type":"code","source":"class BirdCLEFDatasetFromNPY(Dataset):\n    def __init__(self, df, cfg, spectrograms=None, mode=\"train\"):\n        self.df = df\n        self.cfg = cfg\n        self.mode = mode\n\n        self.spectrograms = spectrograms\n        \n        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n        self.species_ids = taxonomy_df['primary_label'].tolist()\n        self.num_classes = len(self.species_ids)\n        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n\n        if 'filepath' not in self.df.columns:\n            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n        \n        if 'samplename' not in self.df.columns:\n            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n\n        sample_names = set(self.df['samplename'])\n        if self.spectrograms:\n            found_samples = sum(1 for name in sample_names if name in self.spectrograms)\n            print(f\"Found {found_samples} matching spectrograms for {mode} dataset out of {len(self.df)} samples\")\n        \n        if cfg.debug:\n            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        samplename = row['samplename']\n        spec = None\n\n        if self.spectrograms and samplename in self.spectrograms:\n            spec = self.spectrograms[samplename]\n        elif not self.cfg.LOAD_DATA:\n            spec = process_audio_file(row['filepath'], self.cfg)\n\n        if spec is None:\n            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n            if self.mode == \"train\":  # Only print warning during training\n                print(f\"Warning: Spectrogram for {samplename} not found and could not be generated\")\n\n        spec = torch.tensor(spec, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n\n        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n            spec = self.apply_spec_augmentations(spec)\n        \n        target = self.encode_label(row['primary_label'])\n        \n        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n            if isinstance(row['secondary_labels'], str):\n                secondary_labels = eval(row['secondary_labels'])\n            else:\n                secondary_labels = row['secondary_labels']\n            \n            for label in secondary_labels:\n                if label in self.label_to_idx:\n                    target[self.label_to_idx[label]] = 1.0\n        \n        return {\n            'melspec': spec, \n            'target': torch.tensor(target, dtype=torch.float32),\n            'filename': row['filename']\n        }\n    \n    def apply_spec_augmentations(self, spec):\n        \"\"\"Apply augmentations to spectrogram\"\"\"\n    \n        # Time masking (horizontal stripes)\n        if random.random() < 0.5:\n            num_masks = random.randint(1, 3)\n            for _ in range(num_masks):\n                width = random.randint(5, 20)\n                start = random.randint(0, spec.shape[2] - width)\n                spec[0, :, start:start+width] = 0\n        \n        # Frequency masking (vertical stripes)\n        if random.random() < 0.5:\n            num_masks = random.randint(1, 3)\n            for _ in range(num_masks):\n                height = random.randint(5, 20)\n                start = random.randint(0, spec.shape[1] - height)\n                spec[0, start:start+height, :] = 0\n        \n        # Random brightness/contrast\n        if random.random() < 0.5:\n            gain = random.uniform(0.8, 1.2)\n            bias = random.uniform(-0.1, 0.1)\n            spec = spec * gain + bias\n            spec = torch.clamp(spec, 0, 1) \n            \n        return spec\n    \n    def encode_label(self, label):\n        \"\"\"Encode label to one-hot vector\"\"\"\n        target = np.zeros(self.num_classes)\n        if label in self.label_to_idx:\n            target[self.label_to_idx[label]] = 1.0\n        return target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:30.042844Z","iopub.execute_input":"2025-04-03T18:50:30.043153Z","iopub.status.idle":"2025-04-03T18:50:30.056479Z","shell.execute_reply.started":"2025-04-03T18:50:30.043131Z","shell.execute_reply":"2025-04-03T18:50:30.055768Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def collate_fn(batch):\n    \"\"\"Custom collate function to handle different sized spectrograms\"\"\"\n    batch = [item for item in batch if item is not None]\n    if len(batch) == 0:\n        return {}\n        \n    result = {key: [] for key in batch[0].keys()}\n    \n    for item in batch:\n        for key, value in item.items():\n            result[key].append(value)\n    \n    for key in result:\n        if key == 'target' and isinstance(result[key][0], torch.Tensor):\n            result[key] = torch.stack(result[key])\n        elif key == 'melspec' and isinstance(result[key][0], torch.Tensor):\n            shapes = [t.shape for t in result[key]]\n            if len(set(str(s) for s in shapes)) == 1:\n                result[key] = torch.stack(result[key])\n    \n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:32.422466Z","iopub.execute_input":"2025-04-03T18:50:32.422794Z","iopub.status.idle":"2025-04-03T18:50:32.428504Z","shell.execute_reply.started":"2025-04-03T18:50:32.422767Z","shell.execute_reply":"2025-04-03T18:50:32.427574Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Model Definition","metadata":{}},{"cell_type":"code","source":"def create_custom_encoder():\n    model = EfficientNetMaskedModel()\n    checkpoint_path = \"/kaggle/input/preatraining_epcoh20/pytorch/default/1/best_model_9.pth\"  # Change this to your checkpoint path\n    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\") \n    model.load_state_dict(checkpoint, strict=False)\n    return model.encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:32.916136Z","iopub.execute_input":"2025-04-03T18:50:32.916493Z","iopub.status.idle":"2025-04-03T18:50:32.920575Z","shell.execute_reply.started":"2025-04-03T18:50:32.916462Z","shell.execute_reply":"2025-04-03T18:50:32.919797Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class BirdCLEFModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        \n        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n        cfg.num_classes = len(taxonomy_df)\n\n        if cfg.model_name!= 'custom':\n            self.backbone = timm.create_model(\n                cfg.model_name,\n                pretrained=cfg.pretrained,\n                in_chans=cfg.in_channels,\n                drop_rate=0.2,\n                drop_path_rate=0.2\n            )\n        else:\n            self.backbone = create_custom_encoder()\n        \n        if 'efficientnet' in cfg.model_name:\n            backbone_out = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n        elif 'resnet' in cfg.model_name:\n            backbone_out = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        elif 'custom' in cfg.model_name:\n            print(\"Using custom pretrained model\")\n            backbone_out = 1280\n        else:\n            backbone_out = self.backbone.get_classifier().in_features\n            self.backbone.reset_classifier(0, '')\n        \n        self.pooling = nn.AdaptiveAvgPool2d(1)\n            \n        self.feat_dim = backbone_out\n        \n        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n        \n        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n        if self.mixup_enabled:\n            self.mixup_alpha = cfg.mixup_alpha\n            \n    def forward(self, x, targets=None):\n    \n        if self.training and self.mixup_enabled and targets is not None:\n            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n            x = mixed_x\n        else:\n            targets_a, targets_b, lam = None, None, None\n        \n        features = self.backbone(x)\n        \n        if isinstance(features, dict):\n            features = features['features']\n            \n        if len(features.shape) == 4:\n            features = self.pooling(features)\n            features = features.view(features.size(0), -1)\n        \n        logits = self.classifier(features)\n        \n        if self.training and self.mixup_enabled and targets is not None:\n            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, \n                                       logits, targets_a, targets_b, lam)\n            return logits, loss\n            \n        return logits\n    \n    def mixup_data(self, x, targets):\n        \"\"\"Applies mixup to the data batch\"\"\"\n        batch_size = x.size(0)\n\n        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n\n        indices = torch.randperm(batch_size).to(x.device)\n\n        mixed_x = lam * x + (1 - lam) * x[indices]\n        \n        return mixed_x, targets, targets[indices], lam\n    \n    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n        \"\"\"Applies mixup to the loss function\"\"\"\n        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:34.791904Z","iopub.execute_input":"2025-04-03T18:50:34.792200Z","iopub.status.idle":"2025-04-03T18:50:34.802054Z","shell.execute_reply.started":"2025-04-03T18:50:34.792179Z","shell.execute_reply":"2025-04-03T18:50:34.801095Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Training Utilities\nWe are configuring our optimization strategy with the AdamW optimizer, cosine scheduling, and the BCEWithLogitsLoss criterion.","metadata":{}},{"cell_type":"code","source":"def get_optimizer(model, cfg):\n  \n    if cfg.optimizer == 'Adam':\n        optimizer = optim.Adam(\n            model.parameters(),\n            lr=cfg.lr,\n            weight_decay=cfg.weight_decay\n        )\n    elif cfg.optimizer == 'AdamW':\n        optimizer = optim.AdamW(\n            model.parameters(),\n            lr=cfg.lr,\n            weight_decay=cfg.weight_decay\n        )\n    elif cfg.optimizer == 'SGD':\n        optimizer = optim.SGD(\n            model.parameters(),\n            lr=cfg.lr,\n            momentum=0.9,\n            weight_decay=cfg.weight_decay\n        )\n    else:\n        raise NotImplementedError(f\"Optimizer {cfg.optimizer} not implemented\")\n        \n    return optimizer\n\ndef get_scheduler(optimizer, cfg):\n   \n    if cfg.scheduler == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(\n            optimizer,\n            T_max=cfg.T_max,\n            eta_min=cfg.min_lr\n        )\n    elif cfg.scheduler == 'ReduceLROnPlateau':\n        scheduler = lr_scheduler.ReduceLROnPlateau(\n            optimizer,\n            mode='min',\n            factor=0.5,\n            patience=2,\n            min_lr=cfg.min_lr,\n            verbose=True\n        )\n    elif cfg.scheduler == 'StepLR':\n        scheduler = lr_scheduler.StepLR(\n            optimizer,\n            step_size=cfg.epochs // 3,\n            gamma=0.5\n        )\n    elif cfg.scheduler == 'OneCycleLR':\n        scheduler = None  \n    else:\n        scheduler = None\n        \n    return scheduler\n\ndef get_criterion(cfg):\n \n    if cfg.criterion == 'BCEWithLogitsLoss':\n        criterion = nn.BCEWithLogitsLoss()\n    else:\n        raise NotImplementedError(f\"Criterion {cfg.criterion} not implemented\")\n        \n    return criterion","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:35.420762Z","iopub.execute_input":"2025-04-03T18:50:35.421056Z","iopub.status.idle":"2025-04-03T18:50:35.428052Z","shell.execute_reply.started":"2025-04-03T18:50:35.421035Z","shell.execute_reply":"2025-04-03T18:50:35.427073Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Training Loop","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, criterion, device, scheduler=None):\n    \n    model.train()\n    losses = []\n    all_targets = []\n    all_outputs = []\n    \n    pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n    \n    for step, batch in pbar:\n    \n        if isinstance(batch['melspec'], list):\n            batch_outputs = []\n            batch_losses = []\n            \n            for i in range(len(batch['melspec'])):\n                inputs = batch['melspec'][i].unsqueeze(0).to(device)\n                target = batch['target'][i].unsqueeze(0).to(device)\n                \n                optimizer.zero_grad()\n                output = model(inputs)\n                loss = criterion(output, target)\n                loss.backward()\n                \n                batch_outputs.append(output.detach().cpu())\n                batch_losses.append(loss.item())\n            \n            optimizer.step()\n            outputs = torch.cat(batch_outputs, dim=0).numpy()\n            loss = np.mean(batch_losses)\n            targets = batch['target'].numpy()\n            \n        else:\n            inputs = batch['melspec'].to(device)\n            targets = batch['target'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            \n            if isinstance(outputs, tuple):\n                outputs, loss = outputs  \n            else:\n                loss = criterion(outputs, targets)\n                \n            loss.backward()\n            optimizer.step()\n            \n            outputs = outputs.detach().cpu().numpy()\n            targets = targets.detach().cpu().numpy()\n        \n        if scheduler is not None and isinstance(scheduler, lr_scheduler.OneCycleLR):\n            scheduler.step()\n            \n        all_outputs.append(outputs)\n        all_targets.append(targets)\n        losses.append(loss if isinstance(loss, float) else loss.item())\n        \n        pbar.set_postfix({\n            'train_loss': np.mean(losses[-10:]) if losses else 0,\n            'lr': optimizer.param_groups[0]['lr']\n        })\n    \n    all_outputs = np.concatenate(all_outputs)\n    all_targets = np.concatenate(all_targets)\n    auc = calculate_auc(all_targets, all_outputs)\n    avg_loss = np.mean(losses)\n    \n    return avg_loss, auc\n\ndef validate(model, loader, criterion, device):\n   \n    model.eval()\n    losses = []\n    all_targets = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Validation\"):\n            if isinstance(batch['melspec'], list):\n                batch_outputs = []\n                batch_losses = []\n                \n                for i in range(len(batch['melspec'])):\n                    inputs = batch['melspec'][i].unsqueeze(0).to(device)\n                    target = batch['target'][i].unsqueeze(0).to(device)\n                    \n                    output = model(inputs)\n                    loss = criterion(output, target)\n                    \n                    batch_outputs.append(output.detach().cpu())\n                    batch_losses.append(loss.item())\n                \n                outputs = torch.cat(batch_outputs, dim=0).numpy()\n                loss = np.mean(batch_losses)\n                targets = batch['target'].numpy()\n                \n            else:\n                inputs = batch['melspec'].to(device)\n                targets = batch['target'].to(device)\n                \n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                \n                outputs = outputs.detach().cpu().numpy()\n                targets = targets.detach().cpu().numpy()\n            \n            all_outputs.append(outputs)\n            all_targets.append(targets)\n            losses.append(loss if isinstance(loss, float) else loss.item())\n    \n    all_outputs = np.concatenate(all_outputs)\n    all_targets = np.concatenate(all_targets)\n    \n    auc = calculate_auc(all_targets, all_outputs)\n    avg_loss = np.mean(losses)\n    \n    return avg_loss, auc\n\ndef calculate_auc(targets, outputs):\n  \n    num_classes = targets.shape[1]\n    aucs = []\n    \n    probs = 1 / (1 + np.exp(-outputs))\n    \n    for i in range(num_classes):\n        \n        if np.sum(targets[:, i]) > 0:\n            class_auc = roc_auc_score(targets[:, i], probs[:, i])\n            aucs.append(class_auc)\n    \n    return np.mean(aucs) if aucs else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:37.710083Z","iopub.execute_input":"2025-04-03T18:50:37.710369Z","iopub.status.idle":"2025-04-03T18:50:37.724109Z","shell.execute_reply.started":"2025-04-03T18:50:37.710350Z","shell.execute_reply":"2025-04-03T18:50:37.723189Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"pre_train = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:39.872825Z","iopub.execute_input":"2025-04-03T18:50:39.873137Z","iopub.status.idle":"2025-04-03T18:50:39.876604Z","shell.execute_reply.started":"2025-04-03T18:50:39.873113Z","shell.execute_reply":"2025-04-03T18:50:39.875818Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Pretraining","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\n\nimport torch.optim as optim\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport os\nimport random\nimport numpy as np\nfrom PIL import Image\nimport torch.nn.functional as F\n\n# Define transformation for spectrogram images\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\n# Dataset to load spectrograms and apply masking\nclass SpectrogramDataset(Dataset):\n    def __init__(self, folder_path, transform=None, mask_ratio=0.5, patch_size=16):\n        self.folder_path = folder_path\n        self.transform = transform\n        self.mask_ratio = mask_ratio\n        self.patch_size = patch_size\n        self.image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.png')]\n\n\n    def mask_spectrogram(self, img):\n        \"\"\"Randomly mask patches of the spectrogram\"\"\"\n        c, h, w = img.shape\n        num_patches_h = h // self.patch_size\n        num_patches_w = w // self.patch_size\n    \n        # Create binary mask with patches\n        mask = torch.ones((num_patches_h, num_patches_w))\n        num_masked = int(self.mask_ratio * num_patches_h * num_patches_w)\n        masked_indices = random.sample(range(num_patches_h * num_patches_w), num_masked)\n    \n        for idx in masked_indices:\n            i, j = divmod(idx, num_patches_w)\n            mask[i, j] = 0  # Set masked patches to 0\n    \n        # Resize mask to match image size\n        mask = mask.unsqueeze(0).unsqueeze(0)  # Shape (1,1,H,W)\n        mask = F.interpolate(mask, size=(h, w), mode=\"bilinear\", align_corners=False)  # Resize smoothly\n        mask = mask.squeeze(0).squeeze(0)  # Remove extra dimensions\n    \n        return img * mask, mask\n\n\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        img = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n        if self.transform:\n            img = self.transform(img)\n        masked_img, mask = self.mask_spectrogram(img)\n        return masked_img, img, mask  # Masked spectrogram, original spectrogram, mask\n\n# Define EfficientNet-B0 based encoder\nclass EfficientNetMaskedModel(nn.Module):\n    def __init__(self, pretrained=True):\n        super(EfficientNetMaskedModel, self).__init__()\n        self.encoder = models.efficientnet_b0(pretrained=pretrained)\n        \n        # Modify first convolution layer to accept 1-channel input\n        self.encoder.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n        \n        self.encoder.classifier = nn.Identity()  # Remove classification head\n        \n        self.decoder = nn.Sequential(\n            nn.Conv2d(1280, 512, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # 7x7 → 14x14\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),  # 14x14 → 28x28\n            nn.ReLU(),\n            nn.ConvTranspose2d(16, 8, kernel_size=4, stride=2, padding=1),   # 28x28 → 56x56\n            nn.ReLU(),\n            nn.ConvTranspose2d(8, 4, kernel_size=4, stride=2, padding=1),    # 56x56 → 112x112\n            nn.ReLU(),\n            nn.ConvTranspose2d(4, 1, kernel_size=4, stride=2, padding=1)     # 112x112 → 224x224\n        )\n\n\n    def forward(self, x):\n        encoded = self.encoder.features(x)  # Extract features\n        reconstructed = self.decoder(encoded)  # Reconstruct masked spectrogram\n        return reconstructed\n\n\n\n# Training setup with validation loop\ndef pre_train_model(data_folder, epochs=10, batch_size=16, lr=1e-3, val_split=0.2,model=None):\n    dataset = SpectrogramDataset(data_folder, transform)\n    \n    # Split dataset into train and validation sets\n    train_size = int((1 - val_split) * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    if model==None:\n        model = EfficientNetMaskedModel(pretrained=True).cuda()\n    criterion = nn.MSELoss()\n    optimizer = optim.AdamW(model.parameters(), lr=lr)\n\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        train_loss = 0\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n        for masked_spectrograms, original_spectrograms, _ in progress_bar:\n            masked_spectrograms, original_spectrograms = masked_spectrograms.cuda(), original_spectrograms.cuda()\n            optimizer.zero_grad()\n            reconstructed = model(masked_spectrograms)\n            # print(reconstructed.shape,original_spectrograms.shape)\n            loss = criterion(reconstructed, original_spectrograms)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n\n        train_loss /= len(train_loader)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for masked_spectrograms, original_spectrograms, _ in val_loader:\n                masked_spectrograms, original_spectrograms = masked_spectrograms.cuda(), original_spectrograms.cuda()\n                reconstructed = model(masked_spectrograms)\n                loss = criterion(reconstructed, original_spectrograms)\n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n        clear_output()\n        # Save best model\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), \"best_model.pth\")\n            print(f\"Best model saved at epoch {epoch + 1}\")\n        \n        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n\n    return model\n\n# Run training\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:40.493647Z","iopub.execute_input":"2025-04-03T18:50:40.494000Z","iopub.status.idle":"2025-04-03T18:50:40.511315Z","shell.execute_reply.started":"2025-04-03T18:50:40.493975Z","shell.execute_reply":"2025-04-03T18:50:40.510467Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Training!","metadata":{}},{"cell_type":"code","source":"\n\ndef run_training(df, cfg):\n    \"\"\"Training function that can either use pre-computed spectrograms or generate them on-the-fly\"\"\"\n\n    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n    species_ids = taxonomy_df['primary_label'].tolist()\n    cfg.num_classes = len(species_ids)\n    \n    if cfg.debug:\n        cfg.update_debug_settings()\n\n    spectrograms = None\n    if cfg.LOAD_DATA:\n        print(\"Loading pre-computed mel spectrograms from NPY file...\")\n        try:\n            spectrograms = np.load(cfg.spectrogram_npy, allow_pickle=True).item()\n            print(f\"Loaded {len(spectrograms)} pre-computed mel spectrograms\")\n        except Exception as e:\n            print(f\"Error loading pre-computed spectrograms: {e}\")\n            print(\"Will generate spectrograms on-the-fly instead.\")\n            cfg.LOAD_DATA = False\n    \n    if not cfg.LOAD_DATA:\n        print(\"Will generate spectrograms on-the-fly during training.\")\n        if 'filepath' not in df.columns:\n            df['filepath'] = cfg.train_datadir + '/' + df.filename\n        if 'samplename' not in df.columns:\n            df['samplename'] = df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n        \n    skf = StratifiedKFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n    \n    best_scores = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['primary_label'])):\n        if fold not in cfg.selected_folds:\n            continue\n            \n        print(f'\\n{\"=\"*30} Fold {fold} {\"=\"*30}')\n        \n        train_df = df.iloc[train_idx].reset_index(drop=True)\n        val_df = df.iloc[val_idx].reset_index(drop=True)\n        \n        print(f'Training set: {len(train_df)} samples')\n        print(f'Validation set: {len(val_df)} samples')\n        \n        train_dataset = BirdCLEFDatasetFromNPY(train_df, cfg, spectrograms=spectrograms, mode='train')\n        val_dataset = BirdCLEFDatasetFromNPY(val_df, cfg, spectrograms=spectrograms, mode='valid')\n        \n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=cfg.batch_size, \n            shuffle=True, \n            num_workers=cfg.num_workers,\n            pin_memory=True,\n            collate_fn=collate_fn,\n            drop_last=True\n        )\n        \n        val_loader = DataLoader(\n            val_dataset, \n            batch_size=cfg.batch_size, \n            shuffle=False, \n            num_workers=cfg.num_workers,\n            pin_memory=True,\n            collate_fn=collate_fn\n        )\n        \n        \n        # model = EfficientNetMaskedModel().to(cfg.device)\n        # checkpoint_path = \"/kaggle/input/pretraining_module/pytorch/default/1/best_model.pth\"  # Change this to your checkpoint path\n        # checkpoint = torch.load(checkpoint_path) \n        # model.load_state_dict(checkpoint, strict=False)\n        # model = model.encoder\n        # model.classifier = nn.Linear(256,num_classes)\n\n        # model  = create_custom_encoder().to(cfg.device)\n        model = BirdCLEFModel(cfg).to(cfg.device)\n\n        # if pre_train:\n        #     # model = pre_train_model(model)\n        #     data_folder = \"/kaggle/input/pretraining-dataset-ss\"\n        #     model = pre_train_model(data_folder,batch_size = 128,model=model)\n        optimizer = get_optimizer(model, cfg)\n        criterion = get_criterion(cfg)\n        \n        if cfg.scheduler == 'OneCycleLR':\n            scheduler = lr_scheduler.OneCycleLR(\n                optimizer,\n                max_lr=cfg.lr,\n                steps_per_epoch=len(train_loader),\n                epochs=cfg.epochs,\n                pct_start=0.1\n            )\n        else:\n            scheduler = get_scheduler(optimizer, cfg)\n        \n        best_auc = 0\n        best_epoch = 0\n        \n        for epoch in range(cfg.epochs):\n            print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n            \n            train_loss, train_auc = train_one_epoch(\n                model, \n                train_loader, \n                optimizer, \n                criterion, \n                cfg.device,\n                scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None\n            )\n            \n            val_loss, val_auc = validate(model, val_loader, criterion, cfg.device)\n\n            if scheduler is not None and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n                if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n                    scheduler.step(val_loss)\n                else:\n                    scheduler.step()\n\n            print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}\")\n            print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n            \n            if val_auc > best_auc:\n                best_auc = val_auc\n                best_epoch = epoch + 1\n                print(f\"New best AUC: {best_auc:.4f} at epoch {best_epoch}\")\n\n                torch.save({\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n                    'epoch': epoch,\n                    'val_auc': val_auc,\n                    'train_auc': train_auc,\n                    'cfg': cfg\n                }, f\"model_fold{fold}.pth\")\n        \n        best_scores.append(best_auc)\n        print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n        \n        # Clear memory\n        del model, optimizer, scheduler, train_loader, val_loader\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"Cross-Validation Results:\")\n    for fold, score in enumerate(best_scores):\n        print(f\"Fold {cfg.selected_folds[fold]}: {score:.4f}\")\n    print(f\"Mean AUC: {np.mean(best_scores):.4f}\")\n    print(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:43.268843Z","iopub.execute_input":"2025-04-03T18:50:43.269133Z","iopub.status.idle":"2025-04-03T18:50:43.282867Z","shell.execute_reply.started":"2025-04-03T18:50:43.269112Z","shell.execute_reply":"2025-04-03T18:50:43.282061Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# model = EfficientNetMaskedModel()\n# checkpoint_path = \"/kaggle/input/pretraining_module/pytorch/default/1/best_model.pth\"  # Change this to your checkpoint path\n# checkpoint = torch.load(checkpoint_path, map_location=\"cpu\") \n# model.load_state_dict(checkpoint, strict=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:46.053575Z","iopub.execute_input":"2025-04-03T18:50:46.053920Z","iopub.status.idle":"2025-04-03T18:50:46.057470Z","shell.execute_reply.started":"2025-04-03T18:50:46.053882Z","shell.execute_reply":"2025-04-03T18:50:46.056488Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n# species_ids = taxonomy_df['primary_label'].tolist()\n# num_classes = len(species_ids)\n# model.encoder.classifier = nn.Linear(256,num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:46.335223Z","iopub.execute_input":"2025-04-03T18:50:46.335513Z","iopub.status.idle":"2025-04-03T18:50:46.338734Z","shell.execute_reply.started":"2025-04-03T18:50:46.335491Z","shell.execute_reply":"2025-04-03T18:50:46.338008Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    import time\n    \n    print(\"\\nLoading training data...\")\n    train_df = pd.read_csv(cfg.train_csv)\n    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n\n    print(\"\\nStarting training...\")\n    print(f\"LOAD_DATA is set to {cfg.LOAD_DATA}\")\n    if cfg.LOAD_DATA:\n        print(\"Using pre-computed mel spectrograms from NPY file\")\n    else:\n        print(\"Will generate spectrograms on-the-fly during training\")\n    \n    run_training(train_df, cfg)\n    \n    print(\"\\nTraining complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:50:47.023002Z","iopub.execute_input":"2025-04-03T18:50:47.023297Z","iopub.status.idle":"2025-04-03T20:21:20.103108Z","shell.execute_reply.started":"2025-04-03T18:50:47.023275Z","shell.execute_reply":"2025-04-03T20:21:20.101994Z"}},"outputs":[{"name":"stdout","text":"\nLoading training data...\n\nStarting training...\nLOAD_DATA is set to True\nUsing pre-computed mel spectrograms from NPY file\nLoading pre-computed mel spectrograms from NPY file...\nLoaded 28564 pre-computed mel spectrograms\n\n============================== Fold 0 ==============================\nTraining set: 22851 samples\nValidation set: 5713 samples\nFound 22851 matching spectrograms for train dataset out of 22851 samples\nFound 5713 matching spectrograms for valid dataset out of 5713 samples\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 170MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Using custom pretrained model\n\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:39<00:00,  7.18it/s, train_loss=0.0322, lr=0.0005]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0418, Train AUC: 0.5103\nVal Loss: 0.0306, Val AUC: 0.5761\nNew best AUC: 0.5761 at epoch 1\n\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0257, lr=0.000488]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0282, Train AUC: 0.6864\nVal Loss: 0.0251, Val AUC: 0.8266\nNew best AUC: 0.8266 at epoch 2\n\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0233, lr=0.000452]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0238, Train AUC: 0.8330\nVal Loss: 0.0218, Val AUC: 0.8895\nNew best AUC: 0.8895 at epoch 3\n\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0225, lr=0.000397]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0214, Train AUC: 0.8870\nVal Loss: 0.0205, Val AUC: 0.9077\nNew best AUC: 0.9077 at epoch 4\n\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0184, lr=0.000328]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0196, Train AUC: 0.9156\nVal Loss: 0.0189, Val AUC: 0.9195\nNew best AUC: 0.9195 at epoch 5\n\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.019, lr=0.000251] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0181, Train AUC: 0.9337\nVal Loss: 0.0179, Val AUC: 0.9261\nNew best AUC: 0.9261 at epoch 6\n\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0164, lr=0.000173]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0169, Train AUC: 0.9470\nVal Loss: 0.0174, Val AUC: 0.9290\nNew best AUC: 0.9290 at epoch 7\n\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.016, lr=0.000104] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0159, Train AUC: 0.9548\nVal Loss: 0.0170, Val AUC: 0.9327\nNew best AUC: 0.9327 at epoch 8\n\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0136, lr=4.87e-5]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0153, Train AUC: 0.9596\nVal Loss: 0.0168, Val AUC: 0.9330\nNew best AUC: 0.9330 at epoch 9\n\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0154, lr=1.32e-5]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0150, Train AUC: 0.9633\nVal Loss: 0.0167, Val AUC: 0.9334\nNew best AUC: 0.9334 at epoch 10\n\nBest AUC for fold 0: 0.9334 at epoch 10\n\n============================== Fold 1 ==============================\nTraining set: 22851 samples\nValidation set: 5713 samples\nFound 22851 matching spectrograms for train dataset out of 22851 samples\nFound 5713 matching spectrograms for valid dataset out of 5713 samples\nUsing custom pretrained model\n\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0301, lr=0.0005]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0419, Train AUC: 0.5092\nVal Loss: 0.0305, Val AUC: 0.6112\nNew best AUC: 0.6112 at epoch 1\n\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0252, lr=0.000488]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0285, Train AUC: 0.6739\nVal Loss: 0.0251, Val AUC: 0.8375\nNew best AUC: 0.8375 at epoch 2\n\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.022, lr=0.000452] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0242, Train AUC: 0.8299\nVal Loss: 0.0219, Val AUC: 0.8940\nNew best AUC: 0.8940 at epoch 3\n\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0212, lr=0.000397]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0217, Train AUC: 0.8880\nVal Loss: 0.0200, Val AUC: 0.9136\nNew best AUC: 0.9136 at epoch 4\n\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0205, lr=0.000328]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0198, Train AUC: 0.9127\nVal Loss: 0.0188, Val AUC: 0.9235\nNew best AUC: 0.9235 at epoch 5\n\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0175, lr=0.000251]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0183, Train AUC: 0.9300\nVal Loss: 0.0177, Val AUC: 0.9336\nNew best AUC: 0.9336 at epoch 6\n\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0165, lr=0.000173]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0170, Train AUC: 0.9465\nVal Loss: 0.0172, Val AUC: 0.9368\nNew best AUC: 0.9368 at epoch 7\n\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0158, lr=0.000104]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0160, Train AUC: 0.9560\nVal Loss: 0.0166, Val AUC: 0.9395\nNew best AUC: 0.9395 at epoch 8\n\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0156, lr=4.87e-5]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0154, Train AUC: 0.9611\nVal Loss: 0.0164, Val AUC: 0.9398\nNew best AUC: 0.9398 at epoch 9\n\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0156, lr=1.32e-5]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0150, Train AUC: 0.9636\nVal Loss: 0.0164, Val AUC: 0.9402\nNew best AUC: 0.9402 at epoch 10\n\nBest AUC for fold 1: 0.9402 at epoch 10\n\n============================== Fold 2 ==============================\nTraining set: 22851 samples\nValidation set: 5713 samples\nFound 22851 matching spectrograms for train dataset out of 22851 samples\nFound 5713 matching spectrograms for valid dataset out of 5713 samples\nUsing custom pretrained model\n\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0299, lr=0.0005]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0416, Train AUC: 0.4976\nVal Loss: 0.0303, Val AUC: 0.6095\nNew best AUC: 0.6095 at epoch 1\n\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0263, lr=0.000488]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0278, Train AUC: 0.7018\nVal Loss: 0.0247, Val AUC: 0.8276\nNew best AUC: 0.8276 at epoch 2\n\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0226, lr=0.000452]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0236, Train AUC: 0.8307\nVal Loss: 0.0216, Val AUC: 0.8953\nNew best AUC: 0.8953 at epoch 3\n\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0212, lr=0.000397]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0211, Train AUC: 0.8893\nVal Loss: 0.0199, Val AUC: 0.9152\nNew best AUC: 0.9152 at epoch 4\n\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0188, lr=0.000328]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0193, Train AUC: 0.9203\nVal Loss: 0.0184, Val AUC: 0.9294\nNew best AUC: 0.9294 at epoch 5\n\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0166, lr=0.000251]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0177, Train AUC: 0.9379\nVal Loss: 0.0174, Val AUC: 0.9367\nNew best AUC: 0.9367 at epoch 6\n\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.015, lr=0.000173] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0164, Train AUC: 0.9512\nVal Loss: 0.0169, Val AUC: 0.9399\nNew best AUC: 0.9399 at epoch 7\n\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.25it/s, train_loss=0.0154, lr=0.000104]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0154, Train AUC: 0.9590\nVal Loss: 0.0165, Val AUC: 0.9431\nNew best AUC: 0.9431 at epoch 8\n\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.014, lr=4.87e-5] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0148, Train AUC: 0.9635\nVal Loss: 0.0163, Val AUC: 0.9434\nNew best AUC: 0.9434 at epoch 9\n\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0136, lr=1.32e-5]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0144, Train AUC: 0.9668\nVal Loss: 0.0162, Val AUC: 0.9441\nNew best AUC: 0.9441 at epoch 10\n\nBest AUC for fold 2: 0.9441 at epoch 10\n\n============================== Fold 3 ==============================\nTraining set: 22851 samples\nValidation set: 5713 samples\nFound 22851 matching spectrograms for train dataset out of 22851 samples\nFound 5713 matching spectrograms for valid dataset out of 5713 samples\nUsing custom pretrained model\n\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.25it/s, train_loss=0.0302, lr=0.0005]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0419, Train AUC: 0.5084\nVal Loss: 0.0303, Val AUC: 0.6384\nNew best AUC: 0.6384 at epoch 1\n\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0256, lr=0.000488]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0274, Train AUC: 0.7145\nVal Loss: 0.0246, Val AUC: 0.8518\nNew best AUC: 0.8518 at epoch 2\n\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0223, lr=0.000452]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0234, Train AUC: 0.8476\nVal Loss: 0.0221, Val AUC: 0.8915\nNew best AUC: 0.8915 at epoch 3\n\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0188, lr=0.000397]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0210, Train AUC: 0.8942\nVal Loss: 0.0198, Val AUC: 0.9153\nNew best AUC: 0.9153 at epoch 4\n\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.019, lr=0.000328] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0191, Train AUC: 0.9221\nVal Loss: 0.0184, Val AUC: 0.9300\nNew best AUC: 0.9300 at epoch 5\n\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0178, lr=0.000251]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0175, Train AUC: 0.9388\nVal Loss: 0.0174, Val AUC: 0.9352\nNew best AUC: 0.9352 at epoch 6\n\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0169, lr=0.000173]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0163, Train AUC: 0.9514\nVal Loss: 0.0168, Val AUC: 0.9413\nNew best AUC: 0.9413 at epoch 7\n\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0149, lr=0.000104]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0153, Train AUC: 0.9594\nVal Loss: 0.0164, Val AUC: 0.9434\nNew best AUC: 0.9434 at epoch 8\n\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0143, lr=4.87e-5]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0146, Train AUC: 0.9644\nVal Loss: 0.0162, Val AUC: 0.9443\nNew best AUC: 0.9443 at epoch 9\n\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.014, lr=1.32e-5] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0143, Train AUC: 0.9667\nVal Loss: 0.0161, Val AUC: 0.9444\nNew best AUC: 0.9444 at epoch 10\n\nBest AUC for fold 3: 0.9444 at epoch 10\n\n============================== Fold 4 ==============================\nTraining set: 22852 samples\nValidation set: 5712 samples\nFound 22852 matching spectrograms for train dataset out of 22852 samples\nFound 5712 matching spectrograms for valid dataset out of 5712 samples\nUsing custom pretrained model\n\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0302, lr=0.0005]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0417, Train AUC: 0.5113\nVal Loss: 0.0306, Val AUC: 0.5865\nNew best AUC: 0.5865 at epoch 1\n\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.026, lr=0.000488] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0283, Train AUC: 0.6697\nVal Loss: 0.0253, Val AUC: 0.8188\nNew best AUC: 0.8188 at epoch 2\n\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.024, lr=0.000452] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0240, Train AUC: 0.8213\nVal Loss: 0.0220, Val AUC: 0.8965\nNew best AUC: 0.8965 at epoch 3\n\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0207, lr=0.000397]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0214, Train AUC: 0.8849\nVal Loss: 0.0203, Val AUC: 0.9153\nNew best AUC: 0.9153 at epoch 4\n\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.019, lr=0.000328] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0194, Train AUC: 0.9181\nVal Loss: 0.0188, Val AUC: 0.9284\nNew best AUC: 0.9284 at epoch 5\n\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.016, lr=0.000251] \nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0180, Train AUC: 0.9348\nVal Loss: 0.0178, Val AUC: 0.9349\nNew best AUC: 0.9349 at epoch 6\n\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0146, lr=0.000173]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0167, Train AUC: 0.9494\nVal Loss: 0.0171, Val AUC: 0.9385\nNew best AUC: 0.9385 at epoch 7\n\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0166, lr=0.000104]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 30.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0158, Train AUC: 0.9569\nVal Loss: 0.0168, Val AUC: 0.9389\nNew best AUC: 0.9389 at epoch 8\n\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.26it/s, train_loss=0.0157, lr=4.87e-5]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0151, Train AUC: 0.9634\nVal Loss: 0.0166, Val AUC: 0.9397\nNew best AUC: 0.9397 at epoch 9\n\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 714/714 [01:38<00:00,  7.27it/s, train_loss=0.0144, lr=1.32e-5]\nValidation: 100%|██████████| 179/179 [00:05<00:00, 31.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0147, Train AUC: 0.9654\nVal Loss: 0.0165, Val AUC: 0.9390\n\nBest AUC for fold 4: 0.9397 at epoch 9\n\n============================================================\nCross-Validation Results:\nFold 0: 0.9334\nFold 1: 0.9402\nFold 2: 0.9441\nFold 3: 0.9444\nFold 4: 0.9397\nMean AUC: 0.9404\n============================================================\n\nTraining complete!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# model = BirdCLEFModel(cfg).to(cfg.device)\nimport os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(r'model_fold5.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:15:09.497658Z","iopub.execute_input":"2025-04-02T19:15:09.497940Z","iopub.status.idle":"2025-04-02T19:15:09.503121Z","shell.execute_reply.started":"2025-04-02T19:15:09.497918Z","shell.execute_reply":"2025-04-02T19:15:09.502312Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model_fold5.pth","text/html":"Path (<tt>model_fold5.pth</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/input/pretraining_module/pytorch/default/1/best_model.pth\"  # Change this to your checkpoint path\ncheckpoint = torch.load(checkpoint_path, map_location=\"cpu\")  # Use \"cuda\" if using GPU\nencoder_state_dict = {k: v for k, v in checkpoint.items() if \"encoder\" in k}\n\n# Load the encoder weights\n# model.load_state_dict(encoder_state_dict, strict=False)\n# Load the state_dict into the model\n# model.load_state_dict(checkpoint, strict=False)  # Set strict=True if keys must match exactly","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms, models\nencoder = models.efficientnet_b0(pretrained=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder.state_dict","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.state_dict","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.state_dict","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}